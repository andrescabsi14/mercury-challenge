{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine Multiple Baserate Metric Distribution for MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import (plot_acf, plot_pacf)\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "import sys\n",
    "sys.path.append((\"../..\"))\n",
    "from Baserate.main.baserate import (\n",
    "    MaBaserate\n",
    ")\n",
    "from ExpressScore.main.express_score import MaScorer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use(\"fivethirtyeight\");\n",
    "\n",
    "import subprocess\n",
    "import shutil\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below we need to specify the warning start date, warning end date, and countries to be scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORE_START_DATE = \"2018-11-04\"\n",
    "SCORE_END_DATE = \"2019-01-05\"\n",
    "MA_COUNTRIES = [\"Iraq\",\"Syria\"]\n",
    "TOP_METS = [\"Lead Time\", \"F1\", \"Quality Score\", \"Mercury Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-31 2018-11-04 2019-01-05 2019-01-09\n",
      "2018-10-16 2017-10-17\n"
     ]
    }
   ],
   "source": [
    "EVT_ABBR = \"MA\"\n",
    "EVT_TYPE = \"Military Activity\"\n",
    "MC_HOME = os.path.abspath(\"../../..\")\n",
    "MCT_HOME = os.path.abspath(\"../../../../mercury-challenge-team\")\n",
    "RESULT_HOME = os.path.join(MCT_HOME, \"data\", \"scoring_results\", \"multiple_baserate\")\n",
    "DOC_PATH = os.path.join(MC_HOME, \"doc\")\n",
    "EVT_DOC_PATH = os.path.join(DOC_PATH, \"scoring\", EVT_ABBR)\n",
    "DATA_PATH = os.path.join(MC_HOME, \"data\")\n",
    "GSR_PATH = os.path.join(DATA_PATH, \"gsr\")\n",
    "MA_GSR_PATH = os.path.join(GSR_PATH, \"ma_gsr\")\n",
    "WARN_PATH = os.path.join(DATA_PATH, \"baserate_warnings\")\n",
    "MA_WARN_PATH = os.path.join(WARN_PATH, \"baserate_ma_warnings\")\n",
    "RESOURCE_PATH = os.path.join(MC_HOME, \"src\", \"Baserate\", \"resources\")\n",
    "HISTORY_LOOKBACK = 365\n",
    "HISTORY_DELAY = 14\n",
    "PARTICIPANT_ID = \"Mercury_MBR\"\n",
    "\n",
    "N_ITER = 100\n",
    "DATE_BUFFER = 4\n",
    "MAX_DIST = 100\n",
    "DIST_BUFFER = 16.66667\n",
    "\n",
    "DEFAULT_FIG_SIZE = (8,5)\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "DATE_FORMAT = \"%Y-%m-%d\"\n",
    "\n",
    "LT_MEAN = 3\n",
    "\n",
    "score_start_date = parse(SCORE_START_DATE)\n",
    "BUFFER_START_DATE = str((score_start_date - datetime.timedelta(DATE_BUFFER)).date())\n",
    "score_end_date = parse(SCORE_END_DATE)\n",
    "BUFFER_END_DATE = str((score_end_date + datetime.timedelta(DATE_BUFFER)).date())\n",
    "print(BUFFER_START_DATE, SCORE_START_DATE, SCORE_END_DATE, BUFFER_END_DATE)\n",
    "\n",
    "hist_end_date = parse(BUFFER_START_DATE) - datetime.timedelta(1 + HISTORY_DELAY)\n",
    "hist_end_date = hist_end_date.strftime(DATE_FORMAT)\n",
    "hist_start_date = parse(BUFFER_START_DATE) - datetime.timedelta(365 + HISTORY_DELAY)\n",
    "hist_start_date = hist_start_date.strftime(DATE_FORMAT)\n",
    "print(hist_end_date, hist_start_date)\n",
    "\n",
    "\n",
    "score_param_filepath = os.path.join(RESULT_HOME, \"Score_MA.json\")\n",
    "warn_scratch_filepath = os.path.join(RESULT_HOME, \"MBR_MA_Warnings.json\")\n",
    "\n",
    "\n",
    "EXPORT_CMD = [\"export\", \"MERC_DB=localhost\"]\n",
    "\n",
    "SCORE_CMD = [\"curl\", \"-H\", \"Content-Type: application/json\", \n",
    "             \"-XPOST\", \"http://localhost:8053/score\", \"-d\",\n",
    "             \"@\"+os.path.abspath(score_param_filepath)]\n",
    "\n",
    "CLEAR_WARN_CMD = [\"curl\", \n",
    "                  \"http://localhost:8029/warning/remove_all/{}\".format(PARTICIPANT_ID)]\n",
    "\n",
    "LOAD_WARN_CMD = [\"curl\", \"-H\", \"Content-Type: application/json\", \n",
    "                 \"-XPOST\", \"http://localhost:8029/warning/dev-intake\", \"--data-binary\", \n",
    "                 \"@\"+os.path.abspath(warn_scratch_filepath)]\n",
    "\n",
    "FILENAME_TEMPLATE = \"MONTHSTR/Baserate_EVTTYPE_ITER_MONTHSTR.json\"\n",
    "DISTN_FILENAME_TEMPLATE = \"MBR Metrics Distribution {} to {}.json\"\n",
    "\n",
    "score_dict_template = {\"Include Matching\": \"false\", \"Start Date\": SCORE_START_DATE,\n",
    "                       \"End Date\": SCORE_END_DATE, \"Performer ID\": PARTICIPANT_ID,\n",
    "                       \"Max Distance\": MAX_DIST, \"Distance Buffer\": DIST_BUFFER, \n",
    "                       \"Date Buffer\": DATE_BUFFER, \"Event Type\": EVT_TYPE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the GSR from the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MA_May_2015.json', 'MA_August_2018.json', 'MA_September_2017.json', 'MA_January_2016.json', 'MA_November_2017.json', 'MA_October_2017.json', 'MA_April_2017.json', 'MA_March_2018.json', 'MA_August_2015.json', 'MA_February_2018.json', 'MA_May_2018.json', 'MA_April_2016.json', 'MA_October_2016.json', 'MA_November_2016.json', 'MA_January_2017.json', 'MA_September_2016.json', 'MA_June_2015.json', 'MA_July_2016.json', 'MA_December_2016.json', 'MA_June_2018.json', 'MA_December_2017.json', 'MA_July_2017.json', 'MA_June_2017.json', 'MA_December_2018.json', 'MA_July_2018.json', 'MA_July_2015.json', 'MA_June_2016.json', 'MA_December_2015.json', 'MA_October_2015.json', 'MA_November_2015.json', 'MA_September_2015.json', 'MA_March_2017.json', 'MA_February_2017.json', 'MA_May_2017.json', 'MA_January_2018.json', 'MA_August_2016.json', 'MA_August_2017.json', 'MA_September_2018.json', 'MA_November_2018.json', 'MA_January_2019.json', 'MA_April_2018.json', 'MA_October_2018.json', 'MA_May_2016.json', 'MA_February_2016.json', 'MA_March_2016.json']\n",
      "99136\n"
     ]
    }
   ],
   "source": [
    "gsr_files = [x for x in os.listdir(MA_GSR_PATH) if x.endswith(\"json\")]\n",
    "print(gsr_files)\n",
    "gsr = []\n",
    "for gf in gsr_files:\n",
    "    with open(os.path.join(MA_GSR_PATH, gf), \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        monthly_gsr = json.load(f)\n",
    "        gsr += monthly_gsr\n",
    "print(len(gsr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['curl', 'http://localhost:8029/warning/remove_all/Mercury_MBR']\n",
      "b'{\"reason\": \"0 warnings removed\", \"Existing warnings updated\": 0, \"Total operations\": 0, \"result\": \"ok\", \"Invalid warnings\": 0, \"New warnings or versions inserted\": 0}' None\n"
     ]
    }
   ],
   "source": [
    "print(CLEAR_WARN_CMD)\n",
    "proc = subprocess.Popen(CLEAR_WARN_CMD, stdout=subprocess.PIPE)\n",
    "clearout, clearerrs = proc.communicate()\n",
    "\n",
    "print(clearout, clearerrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iraq\n",
      "There are 23259 GSR events\n",
      "Iteration 0\n",
      "Iteration 5\n",
      "Iteration 10\n",
      "Iteration 15\n",
      "Iteration 20\n",
      "Iteration 25\n",
      "Iteration 30\n",
      "Iteration 35\n",
      "Iteration 40\n",
      "Iteration 45\n",
      "Iteration 50\n",
      "Iteration 55\n",
      "Iteration 60\n",
      "Iteration 65\n",
      "Iteration 70\n",
      "Iteration 75\n",
      "Iteration 80\n",
      "Iteration 85\n",
      "Iteration 90\n",
      "Iteration 95\n",
      "Syria\n",
      "There are 71658 GSR events\n",
      "Iteration 0\n",
      "Iteration 5\n",
      "Iteration 10\n",
      "Iteration 15\n",
      "Iteration 20\n",
      "Iteration 25\n",
      "Iteration 30\n",
      "Iteration 35\n",
      "Iteration 40\n",
      "Iteration 45\n",
      "Iteration 50\n",
      "Iteration 55\n",
      "Iteration 60\n",
      "Iteration 65\n",
      "Iteration 70\n",
      "Iteration 75\n",
      "Iteration 80\n",
      "Iteration 85\n",
      "Iteration 90\n",
      "Iteration 95\n"
     ]
    }
   ],
   "source": [
    "result_dict = dict()\n",
    "mbr_result_filename = \"MA MBR Results {} to {}.json\".format(SCORE_START_DATE,\n",
    "                                                            SCORE_END_DATE)\n",
    "mbr_result_path = os.path.join(RESULT_HOME, mbr_result_filename)\n",
    "#_COUNTRIES = [\"Egypt\", \"Lebanon\"]\n",
    "_COUNTRIES = MA_COUNTRIES\n",
    "for cc in _COUNTRIES:\n",
    "    print(cc)\n",
    "    cc_path_str = re.sub(\" \", \"_\", cc)\n",
    "    br = MaBaserate(cc)\n",
    "    cc_gsr = [x for x in gsr if x[\"Country\"] == cc]\n",
    "    print(\"There are {} GSR events\".format(len(cc_gsr)))\n",
    "    score_dict = score_dict_template.copy()\n",
    "    score_dict[\"Country\"] = cc\n",
    "    with open(score_param_filepath, \"w\") as f:\n",
    "        json.dump(score_dict, f)\n",
    "    for i in range(N_ITER):\n",
    "        if i%(N_ITER//20) == 0:\n",
    "            print(\"Iteration {}\".format(i))\n",
    "        try:\n",
    "            preds=br.make_predictions(BUFFER_START_DATE, BUFFER_END_DATE, \n",
    "                                      history_delay=HISTORY_DELAY,\n",
    "                                      gsr=cc_gsr)\n",
    "            pred_json = br.convert_warnings_to_json(preds)\n",
    "            pred_json[\"participant_id\"] = PARTICIPANT_ID\n",
    "        except AttributeError:\n",
    "            pred_json = {\"participant_id\": PARTICIPANT_ID, \"payload\": []}\n",
    "\n",
    "        with open(warn_scratch_filepath, \"w\") as f:\n",
    "            json.dump(pred_json, f, ensure_ascii=False, indent=2)\n",
    "        # Load the warnings\n",
    "        proc = subprocess.Popen(LOAD_WARN_CMD, stdout=subprocess.PIPE)\n",
    "        loadout, loaderrs = proc.communicate()\n",
    "        #print(loadout, loaderrs)\n",
    "        # Score the warnings\n",
    "        proc = subprocess.Popen(SCORE_CMD, stdout=subprocess.PIPE)\n",
    "        scoreout, scoreerrs = proc.communicate()\n",
    "        #print(scoreout, scoreerrs)\n",
    "        scoring = json.loads(scoreout.decode(\"utf-8\"))[\"Scoring\"][\"Results\"]\n",
    "        key_ = \"{}_{}\".format(cc, i)\n",
    "        result_dict[key_] = scoring\n",
    "        proc = subprocess.Popen(CLEAR_WARN_CMD, stdout=subprocess.PIPE)\n",
    "        clearout, clearerrs = proc.communicate()\n",
    "        out_path = os.path.join(RESULT_HOME, \n",
    "                                \"{} MBR Results {} to {}.json\".format(cc, SCORE_START_DATE,\n",
    "                                                                      SCORE_END_DATE))\n",
    "\n",
    "    with open(mbr_result_path, \"w\") as f:\n",
    "        json.dump(result_dict, f, ensure_ascii=False, sort_keys=True, indent=2)\n",
    "\n",
    "\n",
    "    #print(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/peterhaglich/Dropbox/Work/IARPA/Mercury/peterhaglich/mercury-challenge-team/data/scoring_results/multiple_baserate/MBR_MA_Warnings.json'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warn_scratch_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/peterhaglich/Dropbox/Work/IARPA/Mercury/peterhaglich/mercury-challenge-team/data/scoring_results/multiple_baserate/Syria MBR Results 2018-11-04 to 2019-01-05.json'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce Distribution Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Iraq': {'F1': {'Mean': 0.86167615711268963, 'Threshold': 0.8647438325789949},\n",
      "          'Lead Time': {'Mean': 4.5489651217351943,\n",
      "                        'Threshold': 4.6137193346152268},\n",
      "          'Mercury Score': {'Mean': 0.80752598820699506,\n",
      "                            'Threshold': 0.80957761939029027},\n",
      "          'Quality Score': {'Mean': 0.75337581930130004,\n",
      "                            'Threshold': 0.75676375938541018}},\n",
      " 'Syria': {'F1': {'Mean': 0.70534560969880655,\n",
      "                  'Threshold': 0.71038788740527037},\n",
      "           'Lead Time': {'Mean': 4.339342653463258,\n",
      "                         'Threshold': 4.3686047801854384},\n",
      "           'Mercury Score': {'Mean': 0.78492404991742659,\n",
      "                             'Threshold': 0.78730080972526839},\n",
      "           'Quality Score': {'Mean': 0.86450249013604674,\n",
      "                             'Threshold': 0.8663864949742146}}}\n"
     ]
    }
   ],
   "source": [
    "distn_dict = dict()\n",
    "for cc in MA_COUNTRIES:\n",
    "    cc_distn_dict = dict()\n",
    "    cc_results = [x for x in result_dict.values() if x[\"Country\"] == cc]\n",
    "    for met in TOP_METS:\n",
    "        cc_distn_dict[met] = dict()\n",
    "        cc_met_values = [x[met] for x in cc_results]\n",
    "        cc_met_mean, cc_met_sd = np.mean(cc_met_values), np.std(cc_met_values)\n",
    "        cc_distn_dict[met][\"Mean\"] = cc_met_mean\n",
    "        cc_distn_dict[met][\"Threshold\"] = cc_met_mean + 0.5*cc_met_sd\n",
    "    distn_dict[cc] = cc_distn_dict\n",
    "pprint(distn_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_filename = DISTN_FILENAME_TEMPLATE.format(SCORE_START_DATE, SCORE_END_DATE)\n",
    "out_path = os.path.join(RESULT_HOME, out_filename)\n",
    "with open(out_path, \"w\") as f:\n",
    "    json.dump(distn_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
